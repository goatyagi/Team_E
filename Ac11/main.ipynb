{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41b26dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            PerfectV  NonPerfectV  Num_Verbs  featureValue Author\n",
      "text01.txt         0            1          1     -0.500000      A\n",
      "text02.txt         0            1          1     -0.500000      A\n",
      "text03.txt         0            1          1     -0.500000      A\n",
      "text04.txt         0            1          1     -0.500000      A\n",
      "text05.txt         0            1          1     -0.500000      A\n",
      "text06.txt         0            1          1     -0.500000      A\n",
      "text07.txt         0            1          1     -0.500000      A\n",
      "text08.txt         0            0          0      0.000000      A\n",
      "text09.txt         0            1          1     -0.500000      A\n",
      "text10.txt         0            1          1     -0.500000      A\n",
      "text11.txt         1            0          1      0.500000      B\n",
      "text12.txt         1            0          1      0.500000      B\n",
      "text13.txt         0            1          1     -0.500000      B\n",
      "text14.txt         0            1          1     -0.500000      B\n",
      "text15.txt         0            1          1     -0.500000      B\n",
      "text16.txt         0            1          1     -0.500000      B\n",
      "text17.txt         0            1          1     -0.500000      B\n",
      "text18.txt         0            1          1     -0.500000      B\n",
      "text19.txt         0            1          1     -0.500000      B\n",
      "text20.txt         0            1          1     -0.500000      B\n",
      "text21.txt         1            1          2      0.000000      C\n",
      "text22.txt         1            1          2      0.000000      C\n",
      "text23.txt         1            1          2      0.000000      C\n",
      "text24.txt         1            1          2      0.000000      C\n",
      "text25.txt         1            1          2      0.000000      C\n",
      "text26.txt         1            0          1      0.500000      C\n",
      "text27.txt         1            1          2      0.000000      C\n",
      "text28.txt         1            1          2      0.000000      C\n",
      "text29.txt         1            1          2      0.000000      C\n",
      "text30.txt         1            1          2      0.000000      C\n",
      "text31.txt         1            0          1      0.500000      D\n",
      "text32.txt         1            0          1      0.500000      D\n",
      "text33.txt         1            0          1      0.500000      D\n",
      "text34.txt         1            0          1      0.500000      D\n",
      "text35.txt         1            0          1      0.500000      D\n",
      "text36.txt         1            0          1      0.500000      D\n",
      "text37.txt         1            0          1      0.500000      D\n",
      "text38.txt         1            1          2      0.000000      D\n",
      "text39.txt         2            0          2      0.666667      D\n",
      "text40.txt         2            0          2      0.666667      D\n"
     ]
    }
   ],
   "source": [
    "# This is the program for making a value for authorship\n",
    "\n",
    "import nltk\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Because I use Jupyter notebook, I need to escape the case that there is .ipynb_checkpoint in a Textdata directory.\n",
    "# by using re, files is the name of file that is in Textdata directory, also that end wit .(txt).\n",
    "files = [ i for i in os.listdir(\"./Data/Textdata/\") if re.match('.*(.txt)$', i)]\n",
    "files.sort()\n",
    "document = []\n",
    "\n",
    "for f in files:\n",
    "    docs = open(\"./Data/Textdata/\"+f, \"r\").read()\n",
    "    document.append(docs)\n",
    "\n",
    "words = []\n",
    "Pos = []\n",
    "\n",
    "for i in range(len(document)):\n",
    "    words.append(nltk.word_tokenize(document[i]))\n",
    "    Pos.append(nltk.pos_tag(words[i]))\n",
    "\n",
    "PerfectV = []\n",
    "NonPerfectV = []\n",
    "Num_Verbs = []\n",
    "\n",
    "for i in range(len(document)):    \n",
    "    \n",
    "    v_p = []\n",
    "    v_np = []\n",
    "    k = 0 \n",
    "    \n",
    "    for j in range (len(Pos[i])):\n",
    "        if k != 0:\n",
    "            k -= 1\n",
    "            continue\n",
    "            \n",
    "        if re.match(\"have|has|had\", Pos[i][j][0].lower()):\n",
    "            if Pos[i][j+1][1] == 'VBN' or Pos[i][j+1][0] == 'had':\n",
    "                v_p.append(Pos[i][j+1][0])\n",
    "                if Pos[i][j+1][0] == 'had':\n",
    "                    k = 1\n",
    "            elif Pos[i][j+2][1] == 'VBN' or Pos[i][j+2][0] == 'had':\n",
    "                v_p.append(Pos[i][j+2][0])\n",
    "                if Pos[i][j+2][0] == 'had':\n",
    "                    k = 2\n",
    "            else:\n",
    "                v_np.append(Pos[i][j][0])\n",
    "        elif Pos[i][j][1].startswith('VB') and Pos[i][j][1] != 'VBN' and Pos[i][j][1] != 'VBG':\n",
    "            v_np.append(Pos[i][j][0])\n",
    "    \n",
    "    PerfectV.append(len(v_p))\n",
    "    NonPerfectV.append(len(v_np))\n",
    "    Num_Verbs.append(len(v_p)+len(v_np))\n",
    "\n",
    "author = pd.read_csv(\"./Data/Authordata/author.csv\", index_col=0)\n",
    "    \n",
    "table = pd.DataFrame({\"PerfectV\": PerfectV,\n",
    "                     \"NonPerfectV\":NonPerfectV,\n",
    "                     \"Num_Verbs\":Num_Verbs}, index=files)\n",
    "\n",
    "table['featureValue'] = (table['PerfectV']-table['NonPerfectV'])/(table['Num_Verbs']+1) # for escaping divide by 0.\n",
    "\n",
    "V = []\n",
    "for i in range(len(author)):\n",
    "    V.append(author['Author'][i])\n",
    "\n",
    "table['Author'] = V\n",
    "\n",
    "print(table)\n",
    "\n",
    "table.to_csv(\"texts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd504fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gotoyagi/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# This is a program for Knn\n",
    "\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts = pd.read_csv(\"texts.csv\", index_col = 0)\n",
    "texts = texts.sample(frac=1, random_state=0)\n",
    "\n",
    "X = texts.loc[:,['featureValue']]\n",
    "Y = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    Y.append(texts['Author'][i])\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.1,random_state=3)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86066023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['had'] []\n",
      "   featureValue\n",
      "0           0.5\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I have had a dog for 6 years.\"\n",
    "\n",
    "words2 = nltk.word_tokenize(sentence)\n",
    "pos2 = nltk.pos_tag(words2)\n",
    "v_p2 = []\n",
    "v_np2 = []\n",
    "num = []\n",
    "flag = 0\n",
    "\n",
    "for j in range(len(pos2)):\n",
    "    if flag != 0:\n",
    "        flag -= 1\n",
    "        continue\n",
    "    if re.match(\"have|has|had\", pos2[j][0].lower()):\n",
    "        if pos2[j+1][1] == 'VBN' or pos2[j+1][0] == 'had':\n",
    "            v_p2.append(pos2[j+1][0])\n",
    "            if pos2[j+1][0] == 'had':\n",
    "                flag = 1\n",
    "        elif pos2[j+2][1] == 'VBN' or pos[j+2][0] == 'had':\n",
    "            v_p2.append(pos2[j+2][0])\n",
    "            if pos2[j+2][0] == 'had':\n",
    "                flag = 2\n",
    "        else:\n",
    "            v_np2.append(pos2[j][0])\n",
    "    elif pos2[j][1].startswith('VB') and pos2[j][1] != 'VBN' and pos2[j][1] != 'VBG':\n",
    "        v_np2.append(pos2[j][0])\n",
    "        \n",
    "num.append(len(words2))\n",
    "print(v_p2, v_np2)\n",
    "P2 = []\n",
    "P2.append(len(v_p2))\n",
    "\n",
    "NP2 = []\n",
    "NP2.append(len(v_np2))\n",
    "\n",
    "NV2 = []\n",
    "NV2.append(len(v_np2) + len(v_p2))\n",
    "\n",
    "table2 = pd.DataFrame({\"PerfectV\":P2,\n",
    "                      \"NonPerfectV\":NP2,\n",
    "                      \"Num_Verbs\":NV2})\n",
    "\n",
    "table2['featureValue'] = (table2[\"PerfectV\"] + table2[\"NonPerfectV\"]) / (table2[\"Num_Verbs\"]+1)\n",
    "print(table2.loc[:,['featureValue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d76cb1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/tykdw3d10hq56s19n07p70mm0000gn/T/ipykernel_47391/3986497664.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpred2_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'featureValue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Train by RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "pred2_Y = rf.predict(table2.loc[:,['featureValue']])\n",
    "\n",
    "print(pred2_Y,Y_test)\n",
    "\n",
    "print(rf.score(X_test, Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553456ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Num_Place  Num_Time  Num_ad  PerfectV  NonPerfectV  Num_Verbs  \\\n",
      "text01.txt          0         0       0         0            1          1   \n",
      "text02.txt          0         1       1         0            1          1   \n",
      "text03.txt          0         0       0         0            1          1   \n",
      "text04.txt          0         0       0         0            1          1   \n",
      "text05.txt          0         0       0         0            1          1   \n",
      "text06.txt          0         1       1         0            1          1   \n",
      "text07.txt          0         0       0         0            1          1   \n",
      "text08.txt          0         0       0         0            0          0   \n",
      "text09.txt          1         1       2         0            1          1   \n",
      "text10.txt          0         1       1         0            1          1   \n",
      "text11.txt          0         1       1         1            0          1   \n",
      "text12.txt          0         0       0         1            0          1   \n",
      "text13.txt          0         0       0         0            1          1   \n",
      "text14.txt          0         0       0         0            1          1   \n",
      "text15.txt          0         0       0         0            1          1   \n",
      "text16.txt          0         1       1         0            1          1   \n",
      "text17.txt          0         0       0         0            1          1   \n",
      "text18.txt          0         0       0         0            1          1   \n",
      "text19.txt          0         0       0         0            1          1   \n",
      "text20.txt          0         0       0         0            1          1   \n",
      "text21.txt          1         1       2         1            1          2   \n",
      "text22.txt          0         0       0         1            1          2   \n",
      "text23.txt          1         1       2         1            1          2   \n",
      "text24.txt          0         1       1         1            1          2   \n",
      "text25.txt          1         1       2         1            1          2   \n",
      "text26.txt          0         1       1         1            0          1   \n",
      "text27.txt          0         0       0         1            1          2   \n",
      "text28.txt          0         0       0         1            1          2   \n",
      "text29.txt          2         0       2         1            1          2   \n",
      "text30.txt          0         0       0         1            1          2   \n",
      "text31.txt          0         0       0         1            0          1   \n",
      "text32.txt          0         0       0         1            0          1   \n",
      "text33.txt          0         0       0         1            0          1   \n",
      "text34.txt          0         0       0         1            0          1   \n",
      "text35.txt          0         0       0         1            0          1   \n",
      "text36.txt          0         0       0         1            0          1   \n",
      "text37.txt          0         0       0         1            0          1   \n",
      "text38.txt          0         0       0         1            1          2   \n",
      "text39.txt          0         0       0         2            0          2   \n",
      "text40.txt          0         0       0         2            0          2   \n",
      "\n",
      "            featureV1  featureV2 Author  \n",
      "text01.txt   0.000000  -0.500000      A  \n",
      "text02.txt  -0.500000  -0.500000      A  \n",
      "text03.txt   0.000000  -0.500000      A  \n",
      "text04.txt   0.000000  -0.500000      A  \n",
      "text05.txt   0.000000  -0.500000      A  \n",
      "text06.txt  -0.500000  -0.500000      A  \n",
      "text07.txt   0.000000  -0.500000      A  \n",
      "text08.txt   0.000000   0.000000      A  \n",
      "text09.txt   0.000000  -0.500000      A  \n",
      "text10.txt  -0.500000  -0.500000      A  \n",
      "text11.txt  -0.500000   0.500000      B  \n",
      "text12.txt   0.000000   0.500000      B  \n",
      "text13.txt   0.000000  -0.500000      B  \n",
      "text14.txt   0.000000  -0.500000      B  \n",
      "text15.txt   0.000000  -0.500000      B  \n",
      "text16.txt  -0.500000  -0.500000      B  \n",
      "text17.txt   0.000000  -0.500000      B  \n",
      "text18.txt   0.000000  -0.500000      B  \n",
      "text19.txt   0.000000  -0.500000      B  \n",
      "text20.txt   0.000000  -0.500000      B  \n",
      "text21.txt   0.000000   0.000000      C  \n",
      "text22.txt   0.000000   0.000000      C  \n",
      "text23.txt   0.000000   0.000000      C  \n",
      "text24.txt  -0.500000   0.000000      C  \n",
      "text25.txt   0.000000   0.000000      C  \n",
      "text26.txt  -0.500000   0.500000      C  \n",
      "text27.txt   0.000000   0.000000      C  \n",
      "text28.txt   0.000000   0.000000      C  \n",
      "text29.txt   0.666667   0.000000      C  \n",
      "text30.txt   0.000000   0.000000      C  \n",
      "text31.txt   0.000000   0.500000      D  \n",
      "text32.txt   0.000000   0.500000      D  \n",
      "text33.txt   0.000000   0.500000      D  \n",
      "text34.txt   0.000000   0.500000      D  \n",
      "text35.txt   0.000000   0.500000      D  \n",
      "text36.txt   0.000000   0.500000      D  \n",
      "text37.txt   0.000000   0.500000      D  \n",
      "text38.txt   0.000000   0.000000      D  \n",
      "text39.txt   0.000000   0.666667      D  \n",
      "text40.txt   0.000000   0.666667      D  \n",
      "The score of rf classifier is  1.0\n",
      "   featureV1  featureV2\n",
      "0        0.0        0.5\n",
      "Program predicate the author of  I had lived in far from Tokyo until yesterday.  is  ['D']\n"
     ]
    }
   ],
   "source": [
    "%run main_RFver.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
