{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e1869921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] ['stayed']\n",
      "[] ['bought']\n",
      "[] ['won']\n",
      "[] ['was']\n",
      "[] ['drove']\n",
      "[] ['ate']\n",
      "[] ['went']\n",
      "[] []\n",
      "[] ['ran']\n",
      "[] ['slept']\n",
      "['finished'] []\n",
      "['visited'] []\n",
      "[] ['is']\n",
      "[] ['is']\n",
      "[] ['was']\n",
      "[] ['talked']\n",
      "[] ['played']\n",
      "[] ['went']\n",
      "[] ['saw']\n",
      "[] ['understood']\n",
      "['finished'] ['came']\n",
      "['played'] ['was']\n",
      "['left'] ['got']\n",
      "['left'] ['arrived']\n",
      "['finished'] ['came']\n",
      "['seen'] []\n",
      "['started'] ['reached']\n",
      "['been'] ['felt']\n",
      "['lived'] ['came']\n",
      "['known'] ['got']\n",
      "['lived'] []\n",
      "['played'] []\n",
      "['been'] []\n",
      "['been'] []\n",
      "['played'] []\n",
      "['played'] []\n",
      "['got'] []\n",
      "['thought'] ['do']\n",
      "['had', 'bought'] ['VBN']\n",
      "['had', 'finished'] ['VBN']\n",
      "            PerfectV  NonPerfectV  Num_words Author\n",
      "text01.txt         0            1          4      A\n",
      "text02.txt         0            1          5      A\n",
      "text03.txt         0            1          7      A\n",
      "text04.txt         0            1          7      A\n",
      "text05.txt         0            1          9      A\n",
      "text06.txt         0            1          5      A\n",
      "text07.txt         0            1          8      A\n",
      "text08.txt         0            0          9      A\n",
      "text09.txt         0            1          5      A\n",
      "text10.txt         0            1          6      A\n",
      "text11.txt         1            0          7      B\n",
      "text12.txt         1            0          6      B\n",
      "text13.txt         0            1          8      B\n",
      "text14.txt         0            1          7      B\n",
      "text15.txt         0            1          9      B\n",
      "text16.txt         0            1          6      B\n",
      "text17.txt         0            1          7      B\n",
      "text18.txt         0            1          8      B\n",
      "text19.txt         0            1          6      B\n",
      "text20.txt         0            1          7      B\n",
      "text21.txt         1            1         11      C\n",
      "text22.txt         1            1         11      C\n",
      "text23.txt         1            1          8      C\n",
      "text24.txt         1            1         12      C\n",
      "text25.txt         1            1         12      C\n",
      "text26.txt         1            0          8      C\n",
      "text27.txt         1            1         10      C\n",
      "text28.txt         1            1         10      C\n",
      "text29.txt         1            1         14      C\n",
      "text30.txt         1            1         13      C\n",
      "text31.txt         1            0          8      D\n",
      "text32.txt         1            0          7      D\n",
      "text33.txt         1            0          5      D\n",
      "text34.txt         1            0          7      D\n",
      "text35.txt         1            0          8      D\n",
      "text36.txt         1            0          7      D\n",
      "text37.txt         1            0         12      D\n",
      "text38.txt         1            1         15      D\n",
      "text39.txt         2            1         14      D\n",
      "text40.txt         2            1         14      D\n"
     ]
    }
   ],
   "source": [
    "# This is the program for making a value for authorship\n",
    "\n",
    "import nltk\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Because I use Jupyter notebook, I need to escape the case that there is .ipynb_checkpoint in a Textdata directory.\n",
    "# by using re, files is the name of file that is in Textdata directory, also that end wit .(txt).\n",
    "files = [ i for i in os.listdir(\"./Data/Textdata/\") if re.match('.*(.txt)$', i)]\n",
    "files.sort()\n",
    "document = []\n",
    "\n",
    "for f in files:\n",
    "    docs = open(\"./Data/Textdata/\"+f, \"r\").read()\n",
    "    document.append(docs)\n",
    "\n",
    "words = []\n",
    "Pos = []\n",
    "\n",
    "for i in range(len(document)):\n",
    "    words.append(nltk.word_tokenize(document[i]))\n",
    "    Pos.append(nltk.pos_tag(words[i]))\n",
    "\n",
    "PerfectV = []\n",
    "NonPerfectV = []\n",
    "Num_words = []\n",
    "\n",
    "for i in range(len(document)):    \n",
    "    \n",
    "    v_p = []\n",
    "    v_np = []\n",
    "    \n",
    "    for j in range (len(Pos[i])):\n",
    "        if re.match(\"have|has|had\", Pos[i][j][0].lower()):\n",
    "            if Pos[i][j+1][1] == 'VBN':\n",
    "                v_p.append(Pos[i][j+1][0])\n",
    "            elif Pos[i][j+2][1] == 'VBN':\n",
    "                v_p.append(Pos[i][j+2][0])\n",
    "            else:\n",
    "                v_np.append(Pos[i][j][0])\n",
    "        elif Pos[i][j][1].startswith('VB') and Pos[i][j][1] != 'VBN' and Pos[i][j][1] != 'VBG':\n",
    "            v_np.append(Pos[i][j][0])\n",
    "    \n",
    "    PerfectV.append(len(v_p))\n",
    "    NonPerfectV.append(len(v_np))\n",
    "    Num_words.append(len(words[i]))\n",
    "    \n",
    "    print(v_p, v_np)\n",
    "\n",
    "author = pd.read_csv(\"./Data/Authordata/author.csv\", index_col=0)\n",
    "    \n",
    "table = pd.DataFrame({\"PerfectV\": PerfectV,\n",
    "                     \"NonPerfectV\":NonPerfectV,\n",
    "                     \"Num_words\":Num_words}, index=files)\n",
    "\n",
    "V = []\n",
    "for i in range(len(author)):\n",
    "    V.append(author['Author'][i])\n",
    "\n",
    "table['Author'] = V\n",
    "\n",
    "print(table)\n",
    "\n",
    "table.to_csv(\"texts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b1123d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            PerfectV  NonPerfectV  Num_words Author\n",
      "text23.txt         1            1          8      C\n",
      "text21.txt         1            1         11      C\n",
      "text26.txt         1            0          8      C\n",
      "text05.txt         0            1          9      A\n",
      "text11.txt         1            0          7      B\n",
      "text16.txt         0            1          6      B\n",
      "text29.txt         1            1         14      C\n",
      "text12.txt         1            0          6      B\n",
      "text19.txt         0            1          6      B\n",
      "text30.txt         1            1         13      C\n",
      "text28.txt         1            1         10      C\n",
      "text36.txt         1            0          7      D\n",
      "text38.txt         1            0         15      D\n",
      "text03.txt         0            1          7      A\n",
      "text40.txt         2            0         14      D\n",
      "text31.txt         1            0          8      D\n",
      "text35.txt         1            0          8      D\n",
      "text17.txt         0            1          7      B\n",
      "text37.txt         1            0         12      D\n",
      "text09.txt         0            1          5      A\n",
      "text14.txt         0            0          7      B\n",
      "text06.txt         0            0          5      A\n",
      "text18.txt         0            1          8      B\n",
      "text15.txt         0            1          9      B\n",
      "text34.txt         1            0          7      D\n",
      "text08.txt         0            0          9      A\n",
      "text33.txt         1            0          5      D\n",
      "text02.txt         0            1          5      A\n",
      "text27.txt         1            1         10      C\n",
      "text13.txt         0            0          8      B\n",
      "text32.txt         1            0          7      D\n",
      "text25.txt         1            1         12      C\n",
      "text07.txt         0            1          8      A\n",
      "text24.txt         1            1         12      C\n",
      "text22.txt         1            1         11      C\n",
      "text20.txt         0            1          7      B\n",
      "text10.txt         0            1          6      A\n",
      "text39.txt         2            0         14      D\n",
      "text04.txt         0            1          7      A\n",
      "text01.txt         0            1          4      A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gotoyagi/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# This is a program for Knn\n",
    "\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts = pd.read_csv(\"texts.csv\", index_col = 0)\n",
    "texts = texts.sample(frac=1, random_state=0)\n",
    "\n",
    "print(texts)\n",
    "X = texts.loc[:,['PerfectV', 'NonPerfectV', 'Num_words']]\n",
    "Y = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    Y.append(texts['Author'][i])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.1,random_state=3)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "12a74a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['been'] []\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gotoyagi/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I have been a student of University of Aizu.\"\n",
    "\n",
    "words2 = nltk.word_tokenize(sentence)\n",
    "pos2 = nltk.pos_tag(words2)\n",
    "v_p2 = []\n",
    "v_np2 = []\n",
    "num = []\n",
    "\n",
    "for j in range(len(pos2)):\n",
    "    if re.match(\"have|has|had\", pos2[j][0].lower()):\n",
    "        if pos2[j+1][1] == 'VBN':\n",
    "            v_p2.append(pos2[j+1][0])\n",
    "        elif pos2[j+2][1] == 'VBN':\n",
    "            v_p2.append(pos2[j+2][0])\n",
    "    elif pos2[j][1] == ('VBD'):\n",
    "        v_np2.append(pos2[j][0])\n",
    "        \n",
    "num.append(len(words2))\n",
    "print(v_p2, v_np2)\n",
    "P2 = []\n",
    "P2.append(len(v_p2))\n",
    "\n",
    "NP2 = []\n",
    "NP2.append(len(v_np2))\n",
    "\n",
    "table2 = pd.DataFrame({\"PerfectV\":P2,\n",
    "                      \"NonPerfectV\":NP2,\n",
    "                      \"Num_words\":num})\n",
    "\n",
    "print(knn.predict(table2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "72cdf064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D'] ['B', 'D', 'C', 'A']\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Train by RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "pred2_Y = rf.predict(table2)\n",
    "\n",
    "print(pred2_Y,Y_test)\n",
    "\n",
    "print(rf.score(X_test, Y_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
